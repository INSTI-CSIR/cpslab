<!DOCTYPE html>
<html lang="en">
<head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <meta name="generator" content="mkdocs-1.6.1, mkdocs-terminal-4.6.0">
     
     
    <link rel="icon" type="image/png" sizes="192x192" href="../img/android-chrome-192x192.png" />
<link rel="icon" type="image/png" sizes="512x512" href="../img/android-chrome-512x512.png" />
<link rel="apple-touch-icon" sizes="180x180" href="../img/apple-touch-icon.png" />
<link rel="shortcut icon" type="image/png" sizes="48x48" href="../img/favicon.ico" />
<link rel="icon" type="image/png" sizes="16x16" href="../img/favicon-16x16.png" />
<link rel="icon" type="image/png" sizes="32x32" href="../img/favicon-32x32.png" />


    
 
<title>The Sojourner - CPSLab</title>


<link href="../css/fontawesome/css/fontawesome.min.css" rel="stylesheet">
<link href="../css/fontawesome/css/solid.min.css" rel="stylesheet">
<link href="../css/normalize.css" rel="stylesheet">
<link href="../css/terminal.css" rel="stylesheet">
<link href="../css/theme.css" rel="stylesheet">
<link href="../css/theme.tile_grid.css" rel="stylesheet">
<link href="../css/theme.footer.css" rel="stylesheet">
<!-- default color palette -->
<link href="../css/palettes/default.css" rel="stylesheet">

<!-- page layout -->
<style>
/* initially set page layout to a one column grid */
.terminal-mkdocs-main-grid {
    display: grid;
    grid-column-gap: 1.4em;
    grid-template-columns: auto;
    grid-template-rows: auto;
}

/*  
*   when side navigation is not hidden, use a two column grid.  
*   if the screen is too narrow, fall back to the initial one column grid layout.
*   in this case the main content will be placed under the navigation panel. 
*/
@media only screen and (min-width: 70em) {
    .terminal-mkdocs-main-grid {
        grid-template-columns: 4fr 9fr;
    }
}</style>



     
    
    

    
    <!-- search css support -->
<link href="../css/search/bootstrap-modal.css" rel="stylesheet">
<!-- search scripts -->
<script>
    var base_url = "..",
    shortcuts = "{}";
</script>
<script src="../js/jquery/jquery-1.10.1.min.js" defer></script>
<script src="../js/bootstrap/bootstrap.min.js" defer></script>
<script src="../js/mkdocs/base.js" defer></script>
    
    
    
    
    <script src="../search/main.js"></script>
    

    
</head>

<body class="terminal"><div class="container">
    <div class="terminal-nav">
        <header class="terminal-logo">
            <div id="mkdocs-terminal-site-name" class="logo terminal-prompt"><a href="/" class="no-style">CPSLab</a></div>
        </header>
        
        <nav class="terminal-menu">
            
            <ul vocab="https://schema.org/" typeof="BreadcrumbList">
                
                
                <li property="itemListElement" typeof="ListItem">
                    <a href=".." class="menu-item " property="item" typeof="WebPage">
                        <span property="name">Home</span>
                    </a>
                    <meta property="position" content="0">
                </li>
                
                
                <li property="itemListElement" typeof="ListItem">
                    <a href="./" class="menu-item active" property="item" typeof="WebPage">
                        <span property="name">The Sojourner</span>
                    </a>
                    <meta property="position" content="1">
                </li>
                
                
                <li property="itemListElement" typeof="ListItem">
                    <a href="../pheno/" class="menu-item " property="item" typeof="WebPage">
                        <span property="name">The Phenonet Testbed</span>
                    </a>
                    <meta property="position" content="2">
                </li>
                
                    
                    


<li property="itemListElement" typeof="ListItem">
    <a href="#" class="menu-item" data-toggle="modal" data-target="#mkdocs_search_modal" property="item" typeof="SearchAction">
        <i aria-hidden="true" class="fa fa-search"></i> <span property="name">Search</span>
    </a>
    <meta property="position" content="3">
</li>
                    
            </ul>
            
        </nav>
    </div>
</div>
        
    <div class="container">
        <div class="terminal-mkdocs-main-grid"><aside id="terminal-mkdocs-side-panel"><nav>
  
    <ul class="terminal-mkdocs-side-nav-items">
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="..">Home</a>
        
    
    
    
  </li>
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
    
        
        <span class="

    terminal-mkdocs-side-nav-item--active">The Sojourner</span>
    
    
    
  </li>
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../pheno/">The Phenonet Testbed</a>
        
    
    
    
  </li>
        
    </ul>
  
</nav><hr>
<nav>
    <ul>
        <li><a href="#autonomous-ground-vehicle-for-simultaneous-localization-and-mapping-slam-with-lidar-and-intel-d435i">Autonomous Ground Vehicle for Simultaneous Localization and Mapping (SLAM) with LiDAR and Intel D435i</a></li>
        <li><a href="#concept-note">Concept Note</a></li><li><a href="#mobility">Mobility</a></li><li><a href="#component-mounting">Component Mounting</a></li><li><a href="#engineering-principles">Engineering Principles</a></li><li><a href="#power-and-sense-management">Power and Sense Management</a></li><li><a href="#research-team">Research Team</a></li>
    </ul>
</nav>
</aside>
            <main id="terminal-mkdocs-main-content">
<section id="mkdocs-terminal-content">
    <h1 id="autonomous-ground-vehicle-for-simultaneous-localization-and-mapping-slam-with-lidar-and-intel-d435i"><a href="https://github.com/adoodevv/pathfinders">Autonomous Ground Vehicle for Simultaneous Localization and Mapping (SLAM) with LiDAR and Intel D435i</a></h1>
<p><img alt="autonomous car build" src="../img/autocar.jpg" /></p>
<h2 id="concept-note">Concept Note</h2>
<p><strong>Relevance of Autonomous Ground Vehicles for Simultaneous Localization and Mapping (SLAM) Using RPLIDAR and Camera</strong></p>
<p>Autonomous ground vehicles (AGVs) equipped with SLAM technology have become vital in modern applications such as ground observatories, autonomous transportation, and precision agriculture. </p>
<p>The integration of RPLIDAR (a rotational laser scanner) and cameras enhances their ability to perceive, map, and navigate complex environments effectively. Below are the key aspects highlighting their relevance: </p>
<ol>
<li>
<p>Enhanced Perception in Dynamic Environments</p>
<p>RPLIDAR: Provides precise distance measurements in a 360-degree field of view, enabling AGVs to detect obstacles, understand terrain, and create detailed environmental maps.
Cameras: Capture visual information for object recognition, semantic segmentation, and texture mapping, complementing the LIDAR data for richer scene understanding.</p>
</li>
<li>
<p>Simultaneous Localization and Mapping (SLAM)</p>
<p>SLAM enables AGVs to build a map of an unknown environment while simultaneously determining their location within it.
The fusion of RPLIDAR and camera data improves SLAM accuracy:
    RPLIDAR: Offers robust spatial mapping in low-light or featureless conditions.
    Camera: Provides visual cues, aiding in feature extraction and alignment where LIDAR might struggle (e.g., smooth surfaces).</p>
</li>
<li>
<p>Applications in Ground Observatories</p>
<p>Environmental Monitoring: AGVs equipped with SLAM can autonomously navigate rough terrains, collecting geospatial and ecological data. Precision Mapping: Facilitates detailed mapping for ground observatories in agriculture, geology, and conservation, helping scientists study terrain and habitats more efficiently.</p>
</li>
<li>
<p>Applications in Autonomous Vehicles</p>
<p>Navigation and Path Planning: Combines the strengths of LIDAR and cameras to avoid obstacles, follow paths, and adapt to dynamic environments.
Urban and Off-Road Scenarios: Enables safe operation in diverse conditions, from city streets to rugged outdoor terrains.</p>
</li>
<li>
<p>Advantages of Multisensor Integration</p>
<p>Redundancy and Complementarity: The combination of RPLIDAR and cameras provides robustness against sensor failures or limitations. Cost-Effective Deployment: RPLIDAR systems are relatively affordable compared to higher-end LIDAR systems, making them suitable for wide adoption in research and industry.</p>
</li>
<li>
<p>Future Prospects</p>
<p>As SLAM algorithms advance, AGVs equipped with RPLIDAR and cameras will play a pivotal role in automating ground observatories and transportation systems, enhancing efficiency, safety, and scalability.</p>
</li>
</ol>
<h2 id="mobility">Mobility</h2>
<h3 id="vehicle-chassis">Vehicle Chassis</h3>
<p>The project is based on the LaTrax 1/18 Rally chassis (Model #75054-5), which provides a solid foundation for the autonomous vehicle. Key specifications include:</p>
<ul>
<li>Length: 265 mm (10.4 inches)</li>
<li>Width (Track): 125 mm (4.92 inches) both front and rear</li>
<li>Height: 90 mm (3.5 inches)</li>
<li>Wheelbase: 165 mm (6.5 inches)</li>
<li>Weight: 554 g (19.5 ounces) with battery, 430 g (15.2 ounces) without battery</li>
<li>Chassis Material: Molded composite Nylon monocoque</li>
</ul>
<p>This chassis was chosen for its compact size, lightweight design, and durability.</p>
<h3 id="motor-selection-and-implementation">Motor Selection and Implementation</h3>
<p>The LaTrax chassis comes with a 370 brushed motor. For autonomous operation, this motor is retained and controlled using the following components:</p>
<ul>
<li>ESC: Comes with Latrax chassis The modelâ€™s ESC is an extemely powerful electronic device capable of delivering high current.</li>
</ul>
<h3 id="steering-system">Steering System</h3>
<p>The original steering system uses a bellcrank mechanism. For autonomous control, this has been modified to use a servo motor, controlled by:</p>
<ul>
<li>Arduino Nano: This allows for accurate steering control managed by the Jetson Orin Nano.</li>
</ul>
<h3 id="drive-system">Drive System</h3>
<ul>
<li>Type: Shaft-driven 4WD</li>
<li>Transmission: 14T pinion / 54T spur</li>
<li>Gear Ratio: 2.5:1 (internal), 9.64:1 (overall, stock)</li>
<li>Differential: Gear type</li>
<li>Gear Pitch: 0.5 Mod</li>
</ul>
<p>This 4WD system provides excellent traction and stability, which is crucial for autonomous operation in various terrains.</p>
<h2 id="component-mounting">Component Mounting</h2>
<p>A custom base plate has been designed and fabricated to mount all the additional components required for autonomous operation. This includes:</p>
<ul>
<li>RPLidar</li>
<li>Intel D435i RealSense Depth Camera</li>
<li>Nvidia Jetson Orin Nano</li>
<li>L298N motor driver</li>
<li>ESC 2 Halo ring switches</li>
</ul>
<p>The base plate serves as a central mounting point, ensuring all components are securely attached and properly positioned. Additional custom mounts have been created for:</p>
<ul>
<li>Camera mount: Attaches the Intel D435i camera to the base plate.</li>
<li>Base mount: Connects the entire setup (base plate with all components) to the LaTrax chassis.</li>
</ul>
<p>These custom mounts ensure proper alignment and stability of all components during operation.</p>
<h2 id="engineering-principles">Engineering Principles</h2>
<h3 id="speed">Speed</h3>
<p>The stock motor and gearing provide a balance between speed and torque. The overall drive ratio of 9.64:1 allows for good low-speed control, which is essential for precise autonomous movement.</p>
<h3 id="torque">Torque</h3>
<p>The gearing system provides ample torque for the vehicle's size and weight. This ensures good acceleration and climbing ability, which are important for navigating various terrains autonomously.</p>
<h3 id="power">Power</h3>
<p>The 370 brushed motor, combined with the stock 6V from the NiMH battery, provides sufficient power for the vehicle's operations. The power delivery is managed by the ESC, allowing for fine control of the vehicle's movements.</p>
<h2 id="power-and-sense-management">Power and Sense Management</h2>
<p><img alt="power circuit" src="../img/circuit.png" /></p>
<ol>
<li>
<p>Jetson Orin Nano (Primary Controller)</p>
<p>Purpose: Acts as the brain of the system, handling high-level decision-making, sensor data processing, and sending commands to motor controllers. Connections:</p>
<p>RPLidar (Serial Over USB): Collects 360-degree LiDAR data, which is used for mapping, obstacle detection, or navigation.
Intel D435i Camera (Serial Over USB): Provides depth sensing and visual information, useful for object detection, path planning, and visual SLAM.
Arduino Nano (Serial Over USB): Communicates with the Arduino, which manages motor control.</p>
<p>Power Consumption: The Jetson Orin Nano consumes around 5-15W depending on processing load.</p>
</li>
<li>
<p>Arduino Nano (Motor Controller)</p>
<p>Purpose: Receives control commands from the Jetson Orin Nano and translates them into signals for the motor drivers to control the wheels and steering. Connections:</p>
<p>Communicates with the motor driver via PWM signals, allowing precise control over speed and direction.</p>
<p>Power Consumption: Typically consumes 0.25W.</p>
</li>
<li>
<p>RPLidar</p>
<p>Purpose: Provides distance measurements and 2D mapping around the robot for obstacle avoidance.</p>
<p>Power Consumption: Around 3-5W.</p>
</li>
<li>
<p>Intel D435i Depth Camera</p>
<p>Purpose: Offers depth perception to the robot, crucial for tasks like object recognition, depth mapping, and navigation.</p>
<p>Power Consumption: Around 1.5W.</p>
</li>
<li>
<p>Electronic Speed Controller</p>
<p>Purpose: Drives the DC motor responsible for the vehicle's motion. The motor driver allows control of both speed and direction of the motor via PWM inputs. Connections:</p>
<p>Receives PWM signals from the Arduino Nano to control the speed and direction of the 6V brushed motor.</p>
<p>Power Consumption: Minimal, but drives the 6V motor which may consume between 2-4W depending on load.</p>
</li>
<li>
<p>6V DC Brushed Motor</p>
<p>Purpose: Powers the wheels, providing the propulsion needed to move the vehicle.
Power Consumption: Between 2-4W depending on speed and load.</p>
</li>
<li>
<p>Servo Motor</p>
<p>Purpose: Provides steering control for the vehicle (likely Ackermann steering), adjusting the angle of the front wheels.
Power Consumption: Around 0.5-1.5W, varying based on the load and steering angle.</p>
</li>
<li>
<p>Batteries</p>
<p>Purpose: The main power source for the system, 11.1V LiPo, supplies voltage to the Jetson whereas the the 6V NiMH powers the driving motor.
Power Output: 11.1V with a capacity of 2200mAh, providing enough energy to sustain the robot's operations for a moderate duration.</p>
</li>
<li>
<p>Switches</p>
<p>Unordered List ItemPower Switch: Controls the overall power to the system, turning the vehicle on or off.
Program Start Switch: Allows the user to initiate the program on the Jetson Orin Nano, triggering autonomous behavior.</p>
</li>
</ol>
<h3 id="summary-of-power-consumption">Summary of Power Consumption</h3>
<ul>
<li>Jetson Orin Nano: 5-15W</li>
<li>RPLidar: 3-5W</li>
<li>Intel D435i Camera: 1.5W</li>
<li>Arduino Nano: 0.25W</li>
<li>6V Brushed Motor: 2-4W</li>
<li>Servo Motor: 0.5-1.5W</li>
</ul>
<h3 id="reasons-for-selecting-sensors">Reasons for Selecting Sensors</h3>
<p>RPLidar: Provides precise distance measurements and 360-degree scans, making it ideal for SLAM (Simultaneous Localization and Mapping) or obstacle avoidance in dynamic environments.</p>
<p>Intel D435i Depth Camera: Adds 3D vision, essential for depth-based navigation and recognizing objects.</p>
<h2 id="research-team">Research Team</h2>
<p><img alt="Jonathan Adoo" src="../img/adoo.jpg" />
<img alt="Haqq M" src="../img/haqq.jpg" />
<img alt="Dr. Oteng" src="../img/otg.png" />
<img alt="Dr. Ing M. Wilson" src="../img/mw.png" />
<img alt="Awotwi John Paapa" src="../img/ajp.jpg" /></p>
</section>

            </main>
        </div>
        <hr><footer>
    <div class="terminal-mkdocs-footer-grid">
        <div id="terminal-mkdocs-footer-copyright-info">
             Site built with <a href="http://www.mkdocs.org">MkDocs</a> and <a href="https://github.com/ntno/mkdocs-terminal">Terminal for MkDocs</a>.
        </div>
    </div>
</footer>
    </div>

    
    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="alertdialog" aria-modal="true" aria-labelledby="searchModalLabel">
    <div class="modal-dialog modal-lg" role="search">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="searchModalLabel">Search</h5>
                <button type="button" class="close btn btn-default btn-ghost" data-dismiss="modal"><span aria-hidden="true">x</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p id="searchInputLabel">Type to start searching</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" aria-labelledby="searchInputLabel" placeholder="" id="mkdocs-search-query" title="Please enter search terms here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No document matches found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    
    
</body>

</html>