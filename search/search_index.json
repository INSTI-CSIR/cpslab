{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CSIR CYBER-PHYSICAL SYSTEMS LAB (CPSLab)","text":"<p>This Lab is spawned from the CSIR-INSTI Makerspace in an initial partnership with the Mikrobot Academy and the Ghana Robotics Academy Foundation. The CPSLab is open for partnerships beyond this initial collaboration with the aimed of becoming a co-innovative space where like-minded persons gather to work on projects, share tools and expertise as well as learn from each other.</p> <p>The Lab is established as a solution hub based on applied research into accelerating technologies in electronics and telecommunications for providing actionable recommendations targeted at creating new businesses from innovations.</p>"},{"location":"#featured-project","title":"Featured Project","text":"<p>Autonomous Ground Vehicle for Simultaneous Localization and Mapping (SLAM) with LiDAR and Intel D435i</p> <p></p>"},{"location":"autonomous/","title":"Autonomous Ground Vehicle for Simultaneous Localization and Mapping (SLAM) with LiDAR and Intel D435i","text":""},{"location":"autonomous/#concept-note","title":"Concept Note","text":"<p>Relevance of Autonomous Ground Vehicles for Simultaneous Localization and Mapping (SLAM) Using RPLIDAR and Camera</p> <p>Autonomous ground vehicles (AGVs) equipped with SLAM technology have become vital in modern applications such as ground observatories, autonomous transportation, and precision agriculture. </p> <p>The integration of RPLIDAR (a rotational laser scanner) and cameras enhances their ability to perceive, map, and navigate complex environments effectively. Below are the key aspects highlighting their relevance: </p> <ol> <li> <p>Enhanced Perception in Dynamic Environments</p> <p>RPLIDAR: Provides precise distance measurements in a 360-degree field of view, enabling AGVs to detect obstacles, understand terrain, and create detailed environmental maps. Cameras: Capture visual information for object recognition, semantic segmentation, and texture mapping, complementing the LIDAR data for richer scene understanding.</p> </li> <li> <p>Simultaneous Localization and Mapping (SLAM)</p> <p>SLAM enables AGVs to build a map of an unknown environment while simultaneously determining their location within it. The fusion of RPLIDAR and camera data improves SLAM accuracy:     RPLIDAR: Offers robust spatial mapping in low-light or featureless conditions.     Camera: Provides visual cues, aiding in feature extraction and alignment where LIDAR might struggle (e.g., smooth surfaces).</p> </li> <li> <p>Applications in Ground Observatories</p> <p>Environmental Monitoring: AGVs equipped with SLAM can autonomously navigate rough terrains, collecting geospatial and ecological data. Precision Mapping: Facilitates detailed mapping for ground observatories in agriculture, geology, and conservation, helping scientists study terrain and habitats more efficiently.</p> </li> <li> <p>Applications in Autonomous Vehicles</p> <p>Navigation and Path Planning: Combines the strengths of LIDAR and cameras to avoid obstacles, follow paths, and adapt to dynamic environments. Urban and Off-Road Scenarios: Enables safe operation in diverse conditions, from city streets to rugged outdoor terrains.</p> </li> <li> <p>Advantages of Multisensor Integration</p> <p>Redundancy and Complementarity: The combination of RPLIDAR and cameras provides robustness against sensor failures or limitations. Cost-Effective Deployment: RPLIDAR systems are relatively affordable compared to higher-end LIDAR systems, making them suitable for wide adoption in research and industry.</p> </li> <li> <p>Future Prospects</p> <p>As SLAM algorithms advance, AGVs equipped with RPLIDAR and cameras will play a pivotal role in automating ground observatories and transportation systems, enhancing efficiency, safety, and scalability.</p> </li> </ol>"},{"location":"autonomous/#mobility","title":"Mobility","text":""},{"location":"autonomous/#vehicle-chassis","title":"Vehicle Chassis","text":"<p>The project is based on the LaTrax 1/18 Rally chassis (Model #75054-5), which provides a solid foundation for the autonomous vehicle. Key specifications include:</p> <ul> <li>Length: 265 mm (10.4 inches)</li> <li>Width (Track): 125 mm (4.92 inches) both front and rear</li> <li>Height: 90 mm (3.5 inches)</li> <li>Wheelbase: 165 mm (6.5 inches)</li> <li>Weight: 554 g (19.5 ounces) with battery, 430 g (15.2 ounces) without battery</li> <li>Chassis Material: Molded composite Nylon monocoque</li> </ul> <p>This chassis was chosen for its compact size, lightweight design, and durability.</p>"},{"location":"autonomous/#motor-selection-and-implementation","title":"Motor Selection and Implementation","text":"<p>The LaTrax chassis comes with a 370 brushed motor. For autonomous operation, this motor is retained and controlled using the following components:</p> <ul> <li>ESC: Comes with Latrax chassis The model\u2019s ESC is an extemely powerful electronic device capable of delivering high current.</li> </ul>"},{"location":"autonomous/#steering-system","title":"Steering System","text":"<p>The original steering system uses a bellcrank mechanism. For autonomous control, this has been modified to use a servo motor, controlled by:</p> <ul> <li>Arduino Nano: This allows for accurate steering control managed by the Jetson Orin Nano.</li> </ul>"},{"location":"autonomous/#drive-system","title":"Drive System","text":"<ul> <li>Type: Shaft-driven 4WD</li> <li>Transmission: 14T pinion / 54T spur</li> <li>Gear Ratio: 2.5:1 (internal), 9.64:1 (overall, stock)</li> <li>Differential: Gear type</li> <li>Gear Pitch: 0.5 Mod</li> </ul> <p>This 4WD system provides excellent traction and stability, which is crucial for autonomous operation in various terrains.</p>"},{"location":"autonomous/#component-mounting","title":"Component Mounting","text":"<p>A custom base plate has been designed and fabricated to mount all the additional components required for autonomous operation. This includes:</p> <ul> <li>RPLidar</li> <li>Intel D435i RealSense Depth Camera</li> <li>Nvidia Jetson Orin Nano</li> <li>L298N motor driver</li> <li>ESC 2 Halo ring switches</li> </ul> <p>The base plate serves as a central mounting point, ensuring all components are securely attached and properly positioned. Additional custom mounts have been created for:</p> <ul> <li>Camera mount: Attaches the Intel D435i camera to the base plate.</li> <li>Base mount: Connects the entire setup (base plate with all components) to the LaTrax chassis.</li> </ul> <p>These custom mounts ensure proper alignment and stability of all components during operation.</p>"},{"location":"autonomous/#engineering-principles","title":"Engineering Principles","text":""},{"location":"autonomous/#speed","title":"Speed","text":"<p>The stock motor and gearing provide a balance between speed and torque. The overall drive ratio of 9.64:1 allows for good low-speed control, which is essential for precise autonomous movement.</p>"},{"location":"autonomous/#torque","title":"Torque","text":"<p>The gearing system provides ample torque for the vehicle's size and weight. This ensures good acceleration and climbing ability, which are important for navigating various terrains autonomously.</p>"},{"location":"autonomous/#power","title":"Power","text":"<p>The 370 brushed motor, combined with the stock 6V from the NiMH battery, provides sufficient power for the vehicle's operations. The power delivery is managed by the ESC, allowing for fine control of the vehicle's movements.</p>"},{"location":"autonomous/#power-and-sense-management","title":"Power and Sense Management","text":"<ol> <li> <p>Jetson Orin Nano (Primary Controller)</p> <p>Purpose: Acts as the brain of the system, handling high-level decision-making, sensor data processing, and sending commands to motor controllers. Connections:</p> <p>RPLidar (Serial Over USB): Collects 360-degree LiDAR data, which is used for mapping, obstacle detection, or navigation. Intel D435i Camera (Serial Over USB): Provides depth sensing and visual information, useful for object detection, path planning, and visual SLAM. Arduino Nano (Serial Over USB): Communicates with the Arduino, which manages motor control.</p> <p>Power Consumption: The Jetson Orin Nano consumes around 5-15W depending on processing load.</p> </li> <li> <p>Arduino Nano (Motor Controller)</p> <p>Purpose: Receives control commands from the Jetson Orin Nano and translates them into signals for the motor drivers to control the wheels and steering. Connections:</p> <p>Communicates with the motor driver via PWM signals, allowing precise control over speed and direction.</p> <p>Power Consumption: Typically consumes 0.25W.</p> </li> <li> <p>RPLidar</p> <p>Purpose: Provides distance measurements and 2D mapping around the robot for obstacle avoidance.</p> <p>Power Consumption: Around 3-5W.</p> </li> <li> <p>Intel D435i Depth Camera</p> <p>Purpose: Offers depth perception to the robot, crucial for tasks like object recognition, depth mapping, and navigation.</p> <p>Power Consumption: Around 1.5W.</p> </li> <li> <p>Electronic Speed Controller</p> <p>Purpose: Drives the DC motor responsible for the vehicle's motion. The motor driver allows control of both speed and direction of the motor via PWM inputs. Connections:</p> <p>Receives PWM signals from the Arduino Nano to control the speed and direction of the 6V brushed motor.</p> <p>Power Consumption: Minimal, but drives the 6V motor which may consume between 2-4W depending on load.</p> </li> <li> <p>6V DC Brushed Motor</p> <p>Purpose: Powers the wheels, providing the propulsion needed to move the vehicle. Power Consumption: Between 2-4W depending on speed and load.</p> </li> <li> <p>Servo Motor</p> <p>Purpose: Provides steering control for the vehicle (likely Ackermann steering), adjusting the angle of the front wheels. Power Consumption: Around 0.5-1.5W, varying based on the load and steering angle.</p> </li> <li> <p>Batteries</p> <p>Purpose: The main power source for the system, 11.1V LiPo, supplies voltage to the Jetson whereas the the 6V NiMH powers the driving motor. Power Output: 11.1V with a capacity of 2200mAh, providing enough energy to sustain the robot's operations for a moderate duration.</p> </li> <li> <p>Switches</p> <p>Unordered List ItemPower Switch: Controls the overall power to the system, turning the vehicle on or off. Program Start Switch: Allows the user to initiate the program on the Jetson Orin Nano, triggering autonomous behavior.</p> </li> </ol>"},{"location":"autonomous/#summary-of-power-consumption","title":"Summary of Power Consumption","text":"<ul> <li>Jetson Orin Nano: 5-15W</li> <li>RPLidar: 3-5W</li> <li>Intel D435i Camera: 1.5W</li> <li>Arduino Nano: 0.25W</li> <li>6V Brushed Motor: 2-4W</li> <li>Servo Motor: 0.5-1.5W</li> </ul>"},{"location":"autonomous/#reasons-for-selecting-sensors","title":"Reasons for Selecting Sensors","text":"<p>RPLidar: Provides precise distance measurements and 360-degree scans, making it ideal for SLAM (Simultaneous Localization and Mapping) or obstacle avoidance in dynamic environments.</p> <p>Intel D435i Depth Camera: Adds 3D vision, essential for depth-based navigation and recognizing objects.</p>"},{"location":"autonomous/#research-team","title":"Research Team","text":""},{"location":"pheno/","title":"The Phenonet Testbed","text":""},{"location":"pheno/#concept-note","title":"Concept Note","text":""},{"location":"pheno/#phenonet-construction","title":"Phenonet Construction","text":""},{"location":"pheno/#soil-sensor-kits","title":"Soil Sensor Kits","text":""},{"location":"pheno/#weather-station-design","title":"Weather Station Design","text":""},{"location":"pheno/#lessons-learnt","title":"Lessons Learnt","text":""}]}